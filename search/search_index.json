{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Course description Explore the principles and techniques of virtual and augmented reality. Learn the main properties of human sensory modalities and the principles of the sensory-motor loop involved when interacting with the physical and virtual worlds. Identify technological interfaces and displays used for human-machine interaction. Understand the models and algorithms used for the interactive and real-time multi-modal rendering of the virtual scene. 3 ECTS Credits 18h Lectures 10h Tutorials Learning outcome Basic knowledge on human spatial and multi-modal perception and cognition. Understanding of the main audio-visual rendering techniques. Learn to design and implement a simple VR application. Pre-requisites Basic knowledge on computer graphics, signal processing and programming. Instructors Indira Thouvenin (UTC Compi\u00e8gne) Olivier Warusfel (IRCAM-STMS) Markus Noisternig (IRCAM-STMS) David Poirier-Quinot (Sorbonne University) Installation Softwares required during tutorials: Unity (2021.3.x free student version) + Visual Studio (Windows) or Visual Studio Code (MacOS) Blender (v3.x)","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#course-description","text":"Explore the principles and techniques of virtual and augmented reality. Learn the main properties of human sensory modalities and the principles of the sensory-motor loop involved when interacting with the physical and virtual worlds. Identify technological interfaces and displays used for human-machine interaction. Understand the models and algorithms used for the interactive and real-time multi-modal rendering of the virtual scene. 3 ECTS Credits 18h Lectures 10h Tutorials","title":"Course description"},{"location":"#learning-outcome","text":"Basic knowledge on human spatial and multi-modal perception and cognition. Understanding of the main audio-visual rendering techniques. Learn to design and implement a simple VR application.","title":"Learning outcome"},{"location":"#pre-requisites","text":"Basic knowledge on computer graphics, signal processing and programming.","title":"Pre-requisites"},{"location":"#instructors","text":"Indira Thouvenin (UTC Compi\u00e8gne) Olivier Warusfel (IRCAM-STMS) Markus Noisternig (IRCAM-STMS) David Poirier-Quinot (Sorbonne University)","title":"Instructors"},{"location":"#installation","text":"Softwares required during tutorials: Unity (2021.3.x free student version) + Visual Studio (Windows) or Visual Studio Code (MacOS) Blender (v3.x)","title":"Installation"},{"location":"gallery/","text":"Students projects (2020) Cat at sunset Roam across hills and forests looking for your lost cat. Listen carefully and you may just find it. Between Hollow Knight and Blasphemous A pixel art beat-them-all platformer. Fox scourge A 2D survival game where, controlling a fireball throwing knight, you're in charge of cleaning the streets from wandering foxes. Parkour run Temple run like game with a flare of japanime. Multiplayer FPS An ambitious multi-player first person shooter game. Not finalized, but plenty of interesting concepts here. Procedural maze Wander through a procedural maze, in search of time gems.","title":"Students projects (2020)"},{"location":"gallery/#students-projects-2020","text":"","title":"Students projects (2020)"},{"location":"gallery/#cat-at-sunset","text":"Roam across hills and forests looking for your lost cat. Listen carefully and you may just find it.","title":"Cat at sunset"},{"location":"gallery/#between-hollow-knight-and-blasphemous","text":"A pixel art beat-them-all platformer.","title":"Between Hollow Knight and Blasphemous"},{"location":"gallery/#fox-scourge","text":"A 2D survival game where, controlling a fireball throwing knight, you're in charge of cleaning the streets from wandering foxes.","title":"Fox scourge"},{"location":"gallery/#parkour-run","text":"Temple run like game with a flare of japanime.","title":"Parkour run"},{"location":"gallery/#multiplayer-fps","text":"An ambitious multi-player first person shooter game. Not finalized, but plenty of interesting concepts here.","title":"Multiplayer FPS"},{"location":"gallery/#procedural-maze","text":"Wander through a procedural maze, in search of time gems.","title":"Procedural maze"},{"location":"lectures/","text":"Lectures C1 Perceiving the environment C1.1 Human vision Understanding how human vision works. C1.2 Human audition Understanding how human audition works. C2 Interacting with the environment C2.1 Haptic and vestibular sensations C2.2 Multi-sensory integration Sensory-motor loop, navigation, immersion. C3 Visual rendering models and graphic pipeline C3.1 3D modelling and illumination models C3.2 Perceptual rendering C4 Audio rendering models and technologies C4.1 Spatial audio technologies binaural, ambisonic, vbap, etc. C4.2 Room acoustic modeling and rendering image sources, beam-tracing, radiosity, etc. C5 Multi-modal rendering, 3D interaction, and sensory-motor integration","title":"Lectures"},{"location":"lectures/#lectures","text":"","title":"Lectures"},{"location":"lectures/#c1-perceiving-the-environment","text":"","title":"C1 Perceiving the environment"},{"location":"lectures/#c11-human-vision","text":"Understanding how human vision works.","title":"C1.1 Human vision"},{"location":"lectures/#c12-human-audition","text":"Understanding how human audition works.","title":"C1.2 Human audition"},{"location":"lectures/#c2-interacting-with-the-environment","text":"","title":"C2 Interacting with the environment"},{"location":"lectures/#c21-haptic-and-vestibular-sensations","text":"","title":"C2.1 Haptic and vestibular sensations"},{"location":"lectures/#c22-multi-sensory-integration","text":"Sensory-motor loop, navigation, immersion.","title":"C2.2 Multi-sensory integration"},{"location":"lectures/#c3-visual-rendering-models-and-graphic-pipeline","text":"","title":"C3 Visual rendering models and graphic pipeline"},{"location":"lectures/#c31-3d-modelling-and-illumination-models","text":"","title":"C3.1 3D modelling and illumination models"},{"location":"lectures/#c32-perceptual-rendering","text":"","title":"C3.2 Perceptual rendering"},{"location":"lectures/#c4-audio-rendering-models-and-technologies","text":"","title":"C4 Audio rendering models and technologies"},{"location":"lectures/#c41-spatial-audio-technologies","text":"binaural, ambisonic, vbap, etc.","title":"C4.1 Spatial audio technologies"},{"location":"lectures/#c42-room-acoustic-modeling-and-rendering","text":"image sources, beam-tracing, radiosity, etc.","title":"C4.2 Room acoustic modeling and rendering"},{"location":"lectures/#c5-multi-modal-rendering-3d-interaction-and-sensory-motor-integration","text":"","title":"C5 Multi-modal rendering, 3D interaction, and sensory-motor integration"},{"location":"plan/","text":"Human vision From object to eye to brain eye model (retina, etc.) encoding the information (cones, rods) interpreting the information brain regions brain \"specs\" (refresh rate, resolution, etc.) Mechanisms of 3D visual perception monocular cues (motion parallax, perspective, etc.) binocular cues (parallax, convergence, etc.) Visual rendering / computer graphics: lighting and rasterizing The physics of light propagation Observed propagation phenomenons geometric phenomenon (simple reflections, shadows, etc.) wave phenomenon (interferences, etc.) Decomposing interactions between light and matter absorption scattering diffraction reflection refraction The simulation of light propagation Reproducing interaction between light and matter: global illumination ray-tracing radiosity Reproducing interaction between light and matter: local illumination ambient lighting specular reflection diffuse reflection All inclusive: Principled BSDF Typical rendering pipelines (inverse camera ray-tracing, rasterization, etc.) Stereoscopic rendering Why it's necessary Existing techniques to bring different images to each eye + example use cases Short introduction to general double-camera rendering pipeline as used in VR softwares Anaglyph (alternating colors) Polarization Shutter glasses (alternating time) HMD (one image per eye) etc. Computer vision Introduction to the field, focus course on tracking techniques required for adaptive rendering Adaptive rendering (existing tracking techniques + example use cases) Outside in camera (Kinect structured light, OptiTrack infra-red pulses, leap motion) Inside out camera (e.g. Quest, Hololens) Electromagnetic tracking (TDOA: GPS, flock of birds, GSM, etc.) Internal MEMs (gyroscope, accelerometers, etc.) etc. pros/cons of various techniques (6 DoF vs 3 DoF, precision, latency, intrusiveness, operating conditions, installation, etc.) Visual rendering / computer graphics: from vertex to scene Modeling edges, vertices, faces meshing and topology Texturing / materials textures shaders normal maps, bump maps, specular maps, etc. combining all that into materials Animating armatures weights inverse kinematic Keyframes and IPO curves Physics rendering engine Bounding box (primitive, convex hull, full mesh) Collision detection mechanisms Different types of colliders (interaction vs. rigid body) Scene graph Hierarchy Deep vs shallow copy (Prefabs, etc.) Lighting Different types of lights generally available + pro/cons sun, area, spot, etc. Baking light maps Camera (optional) intrinsic parameters (focal, etc.) perspective vs. orthographic UI objects Post-processing general concept (2D filter) + examples (blur, SSAO, color grading, etc.) A word on perceptual visual optimization Level of Detail Billboard Sky-box Human (spatial) audition From object to ear to brain ear model (auditory canal, etc.) transcoding the information (from oscillation to neural impulses) interpreting the information: brain regions brain \"specs\" phenomenons of auditory perception (masking, loudness, etc.) Mechanisms of 3D audio perception monaural cues binaural cues spatial auditory plasticity Audio field encoding and decoding Encoding models definition of encoding (different from recording) object oriented format sound field (all inclusive) Audio object spatial encoding and decoding (c.f. C4_1) Sound source panning stereo surround VBAP Sound field synthesis WFS Ambisonic Boundary surface control In ear reconstruction binaural transaural Spatial audio recording hardware and techniques Required compared to visuals, as it's not (yet) easy to \"3D model\" sounds Mono Stereo pair Binaural dummy head / in-ear microphones Ambisonic microphone Anechoic room: get rid of all but direct sound Room acoustic simulation The physics of acoustic propagation Observed propagation phenomenons absorption scattering diffraction reflection refraction Room acoustic measurement room impulse response RIR measurement techniques RIR convolution: a simple method to \"simulate\" room acoustics Analyzing an RIR to quantify the acoustic of a room reverberation time mixing time envelopment etc. The simulation of acoustic propagation (c.f. C4_2) (Existing models used to represent acoustic propagation + pros and cons) geometric acoustics models stochastic vs deterministic methods ray-tracing image source simulating diffraction models based on energy consideration Sabine analytic formula radiosity wave based models BEM artificial models FDN statistical reverberation etc. hybrid models From 3D mesh model to 3D acoustic mesh model measuring the acoustic characteristics of physical materials assigning acoustic properties validation of the simulated acoustic Characterization and simulation of source directivity measurement simulation / integration in simulation (optional) Human haptics / kinaesthetic / sense of touch haptics physiology of touch (sensors) how the information is processed by the brain simulating haptics in VR etc. (mimic audio / visual courses) From basic game to VR experience: guidelines the art of motion proprioception how it works (bio sensors + physiology behind) how it challenges VR -> motion sickness how to move in VR teleportation reduce field of view while walking infinite walk (ever changing environment) etc. how to immerse users field of view rendering quality tracking thresholds frame-rate and latency a coherent whole number of stimulated sensory modalities develop the feeling of presence definition important components (c.f. C2_2) multi-sensory integration (c.f. C2_2) sensory interference (who is dominant when more than one is involved) ventriloquism room matching towards cross-modal enhancement Enable near field interactions near field audio rendering (non linear effects, etc.) near field visuals: requires high quality haptics (e.g. vibration of an engine) precise hand / physics simulation UI integration in world (see this site to develop course if need be) Introduction to programming concepts Introduction to programming concepts related to VR applications Existing data types (boolean, floats, arrays, dictionaries, etc.) Object oriented programming (class, methods) Inheritance Synchronous vs. Asynchronous calls","title":"Human vision"},{"location":"plan/#human-vision","text":"From object to eye to brain eye model (retina, etc.) encoding the information (cones, rods) interpreting the information brain regions brain \"specs\" (refresh rate, resolution, etc.) Mechanisms of 3D visual perception monocular cues (motion parallax, perspective, etc.) binocular cues (parallax, convergence, etc.)","title":"Human vision"},{"location":"plan/#visual-rendering-computer-graphics-lighting-and-rasterizing","text":"The physics of light propagation Observed propagation phenomenons geometric phenomenon (simple reflections, shadows, etc.) wave phenomenon (interferences, etc.) Decomposing interactions between light and matter absorption scattering diffraction reflection refraction The simulation of light propagation Reproducing interaction between light and matter: global illumination ray-tracing radiosity Reproducing interaction between light and matter: local illumination ambient lighting specular reflection diffuse reflection All inclusive: Principled BSDF Typical rendering pipelines (inverse camera ray-tracing, rasterization, etc.) Stereoscopic rendering Why it's necessary Existing techniques to bring different images to each eye + example use cases Short introduction to general double-camera rendering pipeline as used in VR softwares Anaglyph (alternating colors) Polarization Shutter glasses (alternating time) HMD (one image per eye) etc.","title":"Visual rendering / computer graphics: lighting and rasterizing"},{"location":"plan/#computer-vision","text":"Introduction to the field, focus course on tracking techniques required for adaptive rendering Adaptive rendering (existing tracking techniques + example use cases) Outside in camera (Kinect structured light, OptiTrack infra-red pulses, leap motion) Inside out camera (e.g. Quest, Hololens) Electromagnetic tracking (TDOA: GPS, flock of birds, GSM, etc.) Internal MEMs (gyroscope, accelerometers, etc.) etc. pros/cons of various techniques (6 DoF vs 3 DoF, precision, latency, intrusiveness, operating conditions, installation, etc.)","title":"Computer vision"},{"location":"plan/#visual-rendering-computer-graphics-from-vertex-to-scene","text":"Modeling edges, vertices, faces meshing and topology Texturing / materials textures shaders normal maps, bump maps, specular maps, etc. combining all that into materials Animating armatures weights inverse kinematic Keyframes and IPO curves Physics rendering engine Bounding box (primitive, convex hull, full mesh) Collision detection mechanisms Different types of colliders (interaction vs. rigid body) Scene graph Hierarchy Deep vs shallow copy (Prefabs, etc.) Lighting Different types of lights generally available + pro/cons sun, area, spot, etc. Baking light maps Camera (optional) intrinsic parameters (focal, etc.) perspective vs. orthographic UI objects Post-processing general concept (2D filter) + examples (blur, SSAO, color grading, etc.) A word on perceptual visual optimization Level of Detail Billboard Sky-box","title":"Visual rendering / computer graphics: from vertex to scene"},{"location":"plan/#human-spatial-audition","text":"From object to ear to brain ear model (auditory canal, etc.) transcoding the information (from oscillation to neural impulses) interpreting the information: brain regions brain \"specs\" phenomenons of auditory perception (masking, loudness, etc.) Mechanisms of 3D audio perception monaural cues binaural cues spatial auditory plasticity","title":"Human (spatial) audition"},{"location":"plan/#audio-field-encoding-and-decoding","text":"Encoding models definition of encoding (different from recording) object oriented format sound field (all inclusive) Audio object spatial encoding and decoding (c.f. C4_1) Sound source panning stereo surround VBAP Sound field synthesis WFS Ambisonic Boundary surface control In ear reconstruction binaural transaural Spatial audio recording hardware and techniques Required compared to visuals, as it's not (yet) easy to \"3D model\" sounds Mono Stereo pair Binaural dummy head / in-ear microphones Ambisonic microphone Anechoic room: get rid of all but direct sound","title":"Audio field encoding and decoding"},{"location":"plan/#room-acoustic-simulation","text":"The physics of acoustic propagation Observed propagation phenomenons absorption scattering diffraction reflection refraction Room acoustic measurement room impulse response RIR measurement techniques RIR convolution: a simple method to \"simulate\" room acoustics Analyzing an RIR to quantify the acoustic of a room reverberation time mixing time envelopment etc. The simulation of acoustic propagation (c.f. C4_2) (Existing models used to represent acoustic propagation + pros and cons) geometric acoustics models stochastic vs deterministic methods ray-tracing image source simulating diffraction models based on energy consideration Sabine analytic formula radiosity wave based models BEM artificial models FDN statistical reverberation etc. hybrid models From 3D mesh model to 3D acoustic mesh model measuring the acoustic characteristics of physical materials assigning acoustic properties validation of the simulated acoustic Characterization and simulation of source directivity measurement simulation / integration in simulation","title":"Room acoustic simulation"},{"location":"plan/#optional-human-haptics-kinaesthetic-sense-of-touch","text":"haptics physiology of touch (sensors) how the information is processed by the brain simulating haptics in VR etc. (mimic audio / visual courses)","title":"(optional) Human haptics / kinaesthetic / sense of touch"},{"location":"plan/#from-basic-game-to-vr-experience-guidelines","text":"the art of motion proprioception how it works (bio sensors + physiology behind) how it challenges VR -> motion sickness how to move in VR teleportation reduce field of view while walking infinite walk (ever changing environment) etc. how to immerse users field of view rendering quality tracking thresholds frame-rate and latency a coherent whole number of stimulated sensory modalities develop the feeling of presence definition important components (c.f. C2_2) multi-sensory integration (c.f. C2_2) sensory interference (who is dominant when more than one is involved) ventriloquism room matching towards cross-modal enhancement Enable near field interactions near field audio rendering (non linear effects, etc.) near field visuals: requires high quality haptics (e.g. vibration of an engine) precise hand / physics simulation UI integration in world (see this site to develop course if need be)","title":"From basic game to VR experience: guidelines"},{"location":"plan/#introduction-to-programming-concepts","text":"Introduction to programming concepts related to VR applications Existing data types (boolean, floats, arrays, dictionaries, etc.) Object oriented programming (class, methods) Inheritance Synchronous vs. Asynchronous calls","title":"Introduction to programming concepts"},{"location":"tutorials/","text":"T1 Game creation 101 (2h) Introduction to game creation workflow. Learn to use the Unity game creation software, understand the general scene creation workflow and how to use its constituting components. Slides Assets T2 Game Programming Patterns (2h) Introduction to C# programing in Unity. Learn the basic patterns on which relies game logic design. Slides Assets T3 Audio Spatialization (2h) Practical introduction to various 3D audio rendering techniques. Learn to use some of the existing frameworks designed to add 3D sound to a Unity scene. T4 Mini-Project (2h) Creation of a VR application from start to finish. Reinvest the skills learned in previous tutorials to design and implement a full fledged game.","title":"Tutorials"},{"location":"tutorials/#t1-game-creation-101-2h","text":"Introduction to game creation workflow. Learn to use the Unity game creation software, understand the general scene creation workflow and how to use its constituting components. Slides Assets","title":"T1 Game creation 101 (2h)"},{"location":"tutorials/#t2-game-programming-patterns-2h","text":"Introduction to C# programing in Unity. Learn the basic patterns on which relies game logic design. Slides Assets","title":"T2 Game Programming Patterns (2h)"},{"location":"tutorials/#t3-audio-spatialization-2h","text":"Practical introduction to various 3D audio rendering techniques. Learn to use some of the existing frameworks designed to add 3D sound to a Unity scene.","title":"T3 Audio Spatialization (2h)"},{"location":"tutorials/#t4-mini-project-2h","text":"Creation of a VR application from start to finish. Reinvest the skills learned in previous tutorials to design and implement a full fledged game.","title":"T4 Mini-Project (2h)"}]}