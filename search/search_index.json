{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#home","title":"Home","text":""},{"location":"#course-description","title":"Course description","text":"<p>Explore the principles and techniques of virtual and augmented reality. Learn the main properties of human sensory modalities and the principles of the sensory-motor loop involved when interacting with the physical and virtual worlds. Identify technological interfaces and displays used for human-machine interaction. Understand the models and algorithms used for the interactive and real-time multi-modal rendering of the virtual scene.</p> <ul> <li>3 ECTS Credits</li> <li>18h Lectures</li> <li>10h Tutorials</li> </ul>"},{"location":"#learning-outcome","title":"Learning outcome","text":"<ul> <li>Basic knowledge on human spatial and multi-modal perception and cognition.</li> <li>Understanding of the main audio-visual rendering techniques.</li> <li>Learn to design and implement a simple VR application.</li> </ul>"},{"location":"#pre-requisites","title":"Pre-requisites","text":"<p>Basic knowledge on computer graphics, signal processing and programming.</p>"},{"location":"#instructors","title":"Instructors","text":"<ul> <li>Indira Thouvenin (UTC Compi\u00e8gne)</li> <li>Olivier Warusfel (IRCAM-STMS)</li> <li>Markus Noisternig (IRCAM-STMS)</li> <li>David Poirier-Quinot (Sorbonne University)</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Softwares required during tutorials:</p> <ul> <li>Unity (v2022.3.x free student version) + Visual Studio (Windows) or Visual Studio Code (MacOS)</li> <li>(optional) Blender (v4.x)</li> </ul>"},{"location":"gallery/","title":"Students projects (2020)","text":""},{"location":"gallery/#cat-at-sunset","title":"Cat at sunset","text":"<p>Roam across hills and forests looking for your lost cat. Listen carefully and you may just find it.</p> <p></p>"},{"location":"gallery/#between-hollow-knight-and-blasphemous","title":"Between Hollow Knight and Blasphemous","text":"<p>A pixel art beat-them-all platformer.</p> <p></p>"},{"location":"gallery/#fox-scourge","title":"Fox scourge","text":"<p>A 2D survival game where, controlling a fireball throwing knight, you're in charge of cleaning the streets from wandering foxes.</p> <p></p>"},{"location":"gallery/#parkour-run","title":"Parkour run","text":"<p>Temple run like game with a flare of japanime.</p> <p></p>"},{"location":"gallery/#multiplayer-fps","title":"Multiplayer FPS","text":"<p>An ambitious multi-player first person shooter game. Not finalized, but plenty of interesting concepts here.</p> <p></p>"},{"location":"gallery/#procedural-maze","title":"Procedural maze","text":"<p>Wander through a procedural maze, in search of time gems.</p> <p></p>"},{"location":"lectures/","title":"Lectures","text":""},{"location":"lectures/#c1-perceiving-the-environment","title":"C1 Perceiving the environment","text":""},{"location":"lectures/#c11-human-vision","title":"C1.1 Human vision","text":"<p>Understanding how human vision works.</p>"},{"location":"lectures/#c12-human-audition","title":"C1.2 Human audition","text":"<p>Understanding how human audition works.</p>"},{"location":"lectures/#c2-interacting-with-the-environment","title":"C2 Interacting with the environment","text":""},{"location":"lectures/#c21-haptic-and-vestibular-sensations","title":"C2.1 Haptic and vestibular sensations","text":""},{"location":"lectures/#c22-multi-sensory-integration","title":"C2.2 Multi-sensory integration","text":"<p>Sensory-motor loop, navigation, immersion.</p>"},{"location":"lectures/#c3-visual-rendering-models-and-graphic-pipeline","title":"C3 Visual rendering models and graphic pipeline","text":""},{"location":"lectures/#c31-3d-modelling-and-illumination-models","title":"C3.1 3D modelling and illumination models","text":""},{"location":"lectures/#c32-perceptual-rendering","title":"C3.2 Perceptual rendering","text":""},{"location":"lectures/#c4-audio-rendering-models-and-technologies","title":"C4 Audio rendering models and technologies","text":""},{"location":"lectures/#c41-spatial-audio-technologies","title":"C4.1 Spatial audio technologies","text":"<p>binaural, ambisonic, vbap, etc.</p>"},{"location":"lectures/#c42-room-acoustic-modeling-and-rendering","title":"C4.2 Room acoustic modeling and rendering","text":"<p>image sources, beam-tracing, radiosity, etc.</p>"},{"location":"lectures/#c5-multi-modal-rendering-3d-interaction-and-sensory-motor-integration","title":"C5 Multi-modal rendering, 3D interaction, and sensory-motor integration","text":""},{"location":"plan/","title":"Human vision","text":"<ul> <li> <p>From object to eye to brain</p> <ul> <li>eye model (retina, etc.)</li> <li>encoding the information (cones, rods)</li> <li>interpreting the information<ul> <li>brain regions</li> <li>brain \"specs\" (refresh rate, resolution, etc.)</li> </ul> </li> </ul> </li> <li> <p>Mechanisms of 3D visual perception</p> <ul> <li>monocular cues (motion parallax, perspective, etc.)</li> <li>binocular cues (parallax, convergence, etc.)</li> </ul> </li> </ul>"},{"location":"plan/#visual-rendering-computer-graphics-lighting-and-rasterizing","title":"Visual rendering / computer graphics: lighting and rasterizing","text":"<ul> <li> <p>The physics of light propagation</p> <ul> <li> <p>Observed propagation phenomenons</p> <ul> <li>geometric phenomenon (simple reflections, shadows, etc.)</li> <li>wave phenomenon (interferences, etc.)</li> </ul> </li> <li> <p>Decomposing interactions between light and matter</p> <ul> <li>absorption</li> <li>scattering</li> <li>diffraction</li> <li>reflection</li> <li>refraction</li> </ul> </li> </ul> </li> <li> <p>The simulation of light propagation</p> <ul> <li>Reproducing interaction between light and matter: global illumination<ul> <li>ray-tracing</li> <li>radiosity</li> </ul> </li> <li>Reproducing interaction between light and matter: local illumination<ul> <li>ambient lighting</li> <li>specular reflection</li> <li>diffuse reflection</li> <li>All inclusive: Principled BSDF</li> </ul> </li> <li>Typical rendering pipelines (inverse camera ray-tracing, rasterization, etc.)</li> </ul> </li> <li> <p>Stereoscopic rendering</p> <ul> <li> <p>Why it's necessary</p> </li> <li> <p>Existing techniques to bring different images to each eye + example use cases</p> <ul> <li>Short introduction to general double-camera rendering pipeline as used in VR softwares</li> <li>Anaglyph (alternating colors)</li> <li>Polarization</li> <li>Shutter glasses (alternating time)</li> <li>HMD (one image per eye)</li> <li>etc.</li> </ul> </li> </ul> </li> </ul>"},{"location":"plan/#computer-vision","title":"Computer vision","text":"<ul> <li> <p>Introduction to the field, focus course on tracking techniques required for adaptive rendering</p> </li> <li> <p>Adaptive rendering (existing tracking techniques + example use cases)</p> <ul> <li>Outside in camera (Kinect structured light, OptiTrack infra-red pulses, leap motion)</li> <li>Inside out camera (e.g. Quest, Hololens)</li> <li>Electromagnetic tracking (TDOA: GPS, flock of birds, GSM, etc.)</li> <li>Internal MEMs (gyroscope, accelerometers, etc.)</li> <li>etc.</li> <li>pros/cons of various techniques (6 DoF vs 3 DoF, precision, latency, intrusiveness, operating conditions, installation, etc.)</li> </ul> </li> </ul>"},{"location":"plan/#visual-rendering-computer-graphics-from-vertex-to-scene","title":"Visual rendering / computer graphics: from vertex to scene","text":"<ul> <li> <p>Modeling</p> <ul> <li>edges, vertices, faces</li> <li>meshing and topology</li> </ul> </li> <li> <p>Texturing / materials</p> <ul> <li>textures</li> <li>shaders</li> <li>normal maps, bump maps, specular maps, etc.</li> <li>combining all that into materials</li> </ul> </li> <li> <p>Animating</p> <ul> <li>armatures</li> <li>weights</li> <li>inverse kinematic</li> <li>Keyframes and IPO curves</li> </ul> </li> <li> <p>Physics rendering engine</p> <ul> <li>Bounding box (primitive, convex hull, full mesh)</li> <li>Collision detection mechanisms</li> <li>Different types of colliders (interaction vs. rigid body)</li> </ul> </li> <li> <p>Scene graph</p> <ul> <li>Hierarchy</li> <li>Deep vs shallow copy (Prefabs, etc.)</li> </ul> </li> <li> <p>Lighting</p> <ul> <li>Different types of lights generally available + pro/cons<ul> <li>sun, area, spot, etc.</li> </ul> </li> <li>Baking light maps</li> </ul> </li> <li> <p>Camera (optional)</p> <ul> <li>intrinsic parameters (focal, etc.)</li> <li>perspective vs. orthographic</li> <li>UI objects</li> </ul> </li> <li> <p>Post-processing</p> <ul> <li>general concept (2D filter) + examples (blur, SSAO, color grading, etc.)</li> </ul> </li> <li> <p>A word on perceptual visual optimization</p> <ul> <li>Level of Detail</li> <li>Billboard</li> <li>Sky-box</li> </ul> </li> </ul>"},{"location":"plan/#human-spatial-audition","title":"Human (spatial) audition","text":"<ul> <li> <p>From object to ear to brain</p> <ul> <li>ear model (auditory canal, etc.)</li> <li>transcoding the information (from oscillation to neural impulses)</li> <li>interpreting the information:<ul> <li>brain regions</li> <li>brain \"specs\"</li> <li>phenomenons of auditory perception (masking, loudness, etc.)</li> </ul> </li> </ul> </li> <li> <p>Mechanisms of 3D audio perception</p> <ul> <li>monaural cues</li> <li>binaural cues</li> <li>spatial auditory plasticity</li> </ul> </li> </ul>"},{"location":"plan/#audio-field-encoding-and-decoding","title":"Audio field encoding and decoding","text":"<ul> <li> <p>Encoding models</p> <ul> <li>definition of encoding (different from recording)</li> <li>object oriented format</li> <li>sound field (all inclusive)</li> </ul> </li> <li> <p>Audio object spatial encoding and decoding (c.f. C4_1)</p> <ul> <li>Sound source panning<ul> <li>stereo</li> <li>surround</li> <li>VBAP</li> </ul> </li> <li>Sound field synthesis<ul> <li>WFS</li> <li>Ambisonic</li> <li>Boundary surface control</li> </ul> </li> <li>In ear reconstruction<ul> <li>binaural</li> <li>transaural</li> </ul> </li> </ul> </li> <li> <p>Spatial audio recording hardware and techniques</p> <ul> <li>Required compared to visuals, as it's not (yet) easy to \"3D model\" sounds</li> <li>Mono</li> <li>Stereo pair</li> <li>Binaural dummy head / in-ear microphones</li> <li>Ambisonic microphone</li> <li>Anechoic room: get rid of all but direct sound</li> </ul> </li> </ul>"},{"location":"plan/#room-acoustic-simulation","title":"Room acoustic simulation","text":"<ul> <li> <p>The physics of acoustic propagation</p> <ul> <li>Observed propagation phenomenons<ul> <li>absorption</li> <li>scattering</li> <li>diffraction</li> <li>reflection</li> <li>refraction</li> </ul> </li> </ul> </li> <li> <p>Room acoustic measurement</p> <ul> <li>room impulse response</li> <li>RIR measurement techniques</li> <li>RIR convolution: a simple method to \"simulate\" room acoustics</li> </ul> </li> <li> <p>Analyzing an RIR to quantify the acoustic of a room</p> <ul> <li>reverberation time</li> <li>mixing time</li> <li>envelopment</li> <li>etc.</li> </ul> </li> <li> <p>The simulation of acoustic propagation (c.f. C4_2) (Existing models used to represent acoustic propagation + pros and cons)</p> <ul> <li>geometric acoustics models<ul> <li>stochastic vs deterministic methods</li> <li>ray-tracing</li> <li>image source</li> <li>simulating diffraction</li> </ul> </li> <li>models based on energy consideration<ul> <li>Sabine analytic formula</li> <li>radiosity</li> </ul> </li> <li>wave based models<ul> <li>BEM</li> </ul> </li> <li>artificial models<ul> <li>FDN</li> <li>statistical reverberation</li> <li>etc.</li> </ul> </li> <li>hybrid models</li> </ul> </li> <li> <p>From 3D mesh model to 3D acoustic mesh model</p> <ul> <li>measuring the acoustic characteristics of physical materials</li> <li>assigning acoustic properties</li> <li>validation of the simulated acoustic</li> </ul> </li> <li> <p>Characterization and simulation of source directivity</p> <ul> <li>measurement</li> <li>simulation / integration in simulation</li> </ul> </li> </ul>"},{"location":"plan/#optional-human-haptics-kinaesthetic-sense-of-touch","title":"(optional) Human haptics / kinaesthetic / sense of touch","text":"<ul> <li> <p>haptics</p> <ul> <li>physiology of touch (sensors)</li> <li>how the information is processed by the brain</li> </ul> </li> <li> <p>simulating haptics in VR</p> </li> <li> <p>etc. (mimic audio / visual courses)</p> </li> </ul>"},{"location":"plan/#from-basic-game-to-vr-experience-guidelines","title":"From basic game to VR experience: guidelines","text":"<ul> <li> <p>the art of motion</p> <ul> <li>proprioception<ul> <li>how it works (bio sensors + physiology behind)</li> <li>how it challenges VR -&gt; motion sickness</li> </ul> </li> <li>how to move in VR<ul> <li>teleportation</li> <li>reduce field of view while walking</li> <li>infinite walk (ever changing environment)</li> <li>etc.</li> </ul> </li> </ul> </li> <li> <p>how to immerse users</p> <ul> <li>field of view</li> <li>rendering quality</li> <li>tracking thresholds</li> <li>frame-rate and latency</li> <li>a coherent whole</li> <li>number of stimulated sensory modalities</li> </ul> </li> <li> <p>develop the feeling of presence</p> <ul> <li>definition</li> <li>important components (c.f. C2_2)</li> </ul> </li> <li> <p>multi-sensory integration (c.f. C2_2)</p> <ul> <li>sensory interference (who is dominant when more than one is involved)<ul> <li>ventriloquism</li> <li>room matching</li> </ul> </li> <li>towards cross-modal enhancement</li> </ul> </li> <li> <p>Enable near field interactions</p> <ul> <li>near field audio rendering (non linear effects, etc.)</li> <li>near field visuals: requires high quality</li> <li>haptics (e.g. vibration of an engine)</li> <li>precise hand / physics simulation</li> </ul> </li> <li> <p>UI integration in world</p> </li> </ul> <p>(see this site to develop course if need be)</p>"},{"location":"plan/#introduction-to-programming-concepts","title":"Introduction to programming concepts","text":"<p>Introduction to programming concepts related to VR applications</p> <ul> <li>Existing data types (boolean, floats, arrays, dictionaries, etc.)</li> <li>Object oriented programming (class, methods)</li> <li>Inheritance</li> <li>Synchronous vs. Asynchronous calls</li> </ul>"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#t1-game-creation-101-2h","title":"T1 Game creation 101 (2h)","text":"<p>Introduction to game creation workflow. Learn to use the Unity game creation software, understand the general scene creation workflow and how to use its constituting components.</p> <ul> <li>Slides</li> <li>Assets</li> </ul> <p>After the tutorial:</p> <ul> <li>Assets master</li> <li>Tutorial video</li> </ul>"},{"location":"tutorials/#t2-game-programming-patterns-2h","title":"T2 Game Programming Patterns (2h)","text":"<p>Introduction to C# programing in Unity. Learn the basic patterns on which relies game logic design.</p> <ul> <li>Slides</li> <li>Assets</li> </ul> <p>After the tutorial:</p> <ul> <li>Assets master</li> <li>Tutorial video</li> </ul>"},{"location":"tutorials/#t3-interfaces-2h","title":"T3 Interfaces (2h)","text":"<p>Hands on introduction to the OSC protocol as an example of technique to simplify integration between applications, frameworks, interfaces, etc. Being able to cherry pick is essential to quickly test and assess interaction designs in VR.</p> <ul> <li>Slides</li> <li>Assets</li> </ul>"},{"location":"tutorials/#t3-mini-project-4h","title":"T3 Mini-Project (4h)","text":"<p>Creation of a VR application from start to finish. Reinvest the skills learned in previous tutorials to design and implement a full fledged game.</p>"}]}